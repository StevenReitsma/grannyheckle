{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/demo/train_data.csv')\n",
    "weights = pd.read_csv('../data/demo/buurt_weights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(\"WijkenEnBuurten\", axis=1).drop(\"SoortRegio\", axis=1).drop(train_data.columns[0], axis=1).drop(\"attributes.TELJAAR\",axis=1)\n",
    "msk = np.random.rand(len(train_data)) < 0.9\n",
    "train_set = train_data[msk]\n",
    "test_set = train_data[~msk]\n",
    "\n",
    "y_train = train_set['attributes.AANTAL_SUMMED'].values\n",
    "X_train = train_set.drop('attributes.AANTAL_SUMMED', axis=1).drop('attributes.AANTAL',axis=1).values\n",
    "y_test = test_set['attributes.AANTAL_SUMMED'].values\n",
    "X_test = test_set.drop('attributes.AANTAL_SUMMED', axis=1).drop('attributes.AANTAL',axis=1).values\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'rmse'},\n",
    "    'num_leaves': 127,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=500,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Start predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "baseline = [np.mean(y_train)] * len(y_test)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "print('The rmse of baseline is:', mean_squared_error(baseline, y_test) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipped = zip(gbm.feature_importance(),train_set.drop('attributes.AANTAL_SUMMED', axis=1).drop('attributes.AANTAL',axis=1).columns[1:])\n",
    "zipped = sorted(zipped, key = lambda t: t[0], reverse=True)\n",
    "for importance, column in zipped:\n",
    "    print(\"Feature {} has an importance weight of {}\".format(column,importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future predictions pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buurtinfo2016 = pd.read_csv('../data/demo/buurtinfo2016.csv')\n",
    "true_labels = pd.read_csv('../data/demo/true_labels.csv',index_col=0, header=None)\n",
    "predictions = pd.read_csv('../data/demo/pred_labels.csv',index_col=0, header=None)\n",
    "weights = weights[weights['WijkenEnBuurten'].isin(buurtinfo2016['WijkenEnBuurten'].values)]\n",
    "weights.index = buurtinfo2016.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_negatives(y_pred, true_2016):\n",
    "    return_list = []\n",
    "    for i, value in enumerate(y_pred):\n",
    "        if value < true_2016[i][0]:\n",
    "            return_list.append(true_2016[i][0])\n",
    "        else:\n",
    "            return_list.append(value)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(weights, buurtinfo2016, true_2016, pred_2016):\n",
    "    for i in range(1,14):\n",
    "        weights_only = weights.copy()\n",
    "        weights_only = weights_only * i\n",
    "        weights_only['WijkenEnBuurten'] = 0\n",
    "        buurtinfo2016_multiplied = buurtinfo2016.add(weights_only,fill_value=0)\n",
    "        diff = true_2016.values - pred_2016.values\n",
    "        diff = np.array(list(map(lambda x: x[0], diff)))\n",
    "        y_pred = gbm.predict(buurtinfo2016_multiplied[buurtinfo2016_multiplied.columns[2:]].values)\n",
    "        \n",
    "        y_pred = y_pred + diff\n",
    "        df_predicted = buurtinfo2016_multiplied[['WijkenEnBuurten']].copy()\n",
    "        df_predicted['year'] = 2016 + i\n",
    "        y_pred[y_pred<0] = 0\n",
    "        y_pred = fix_negatives(y_pred, true_2016.values)\n",
    "        df_predicted['predicted_nr_panels'] = y_pred\n",
    "        df_predicted.to_csv('../data/demo/predictions_{}.csv'.format(2016 + i))\n",
    "        print(\"Predicted {} and wrote to file\".format(2016+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline(weights, buurtinfo2016, true_labels, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lightgbm]",
   "language": "python",
   "name": "conda-env-lightgbm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
