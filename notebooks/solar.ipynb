{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for solar panel prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### First we define our deep-learning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(256, 256, 3))\n",
    "x = BatchNormalization()(inputs)\n",
    "x = Conv2D(filters=16, kernel_size=3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=16, kernel_size=3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D()(x)\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D()(x)\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D()(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D()(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D()(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "model.compile(Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We create image generators that generate train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input, zoom_range=0.1, width_shift_range=10,\n",
    "                               rotation_range=90, vertical_flip=True, horizontal_flip=True, height_shift_range=10,\n",
    "                               fill_mode='reflect').flow_from_directory('../satdata/train', batch_size=batch_size)\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory('../satdata/val', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We train our deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_gen, train_gen.n // batch_size, epochs=2, verbose=1, workers=16, use_multiprocessing=True,\n",
    "                    validation_data=train_gen, validation_steps=val_gen.n // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "model = load_model(\"../new_model.hdf5\")\n",
    "test_gen = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory('../satdata/test_wijchen', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "i = 0\n",
    "for image, name in zip(test_gen, test_gen.filenames):\n",
    "    pred = model.predict(image[0])[0, 1]\n",
    "    preds.append((name, pred))\n",
    "    if pred > 0.97:\n",
    "        i += 1\n",
    "        img = load_img(f\"../satdata/test_wijchen/{name}\")\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        print(f\"{name}: {pred:.2f}\")\n",
    "        \n",
    "test_gen.reset()\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(preds, open('../predictions.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('../predictions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../new_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
